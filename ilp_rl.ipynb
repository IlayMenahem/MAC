{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RL and ILP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multi_taxi import single_taxi_v0, maps\n",
    "import gymnasium as gym\n",
    "\n",
    "from PIL import Image\n",
    "def np_to_pil(img_arr):\n",
    "    return Image.fromarray(img_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_taxi_env = single_taxi_v0.gym_env(\n",
    "    num_passengers=3,\n",
    "    max_fuel=50,\n",
    "    has_standby_action=False,\n",
    "    pickup_only=True,\n",
    "    observation_type='symbolic',\n",
    "    render_mode='human',\n",
    "    domain_map=maps.SMALL_MAP\n",
    ")\n",
    "\n",
    "single_taxi_env = gym.wrappers.FlattenObservation(single_taxi_env)\n",
    "single_taxi_env = gym.wrappers.NormalizeObservation(single_taxi_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "| : | : : |\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "|\u001b[31mP\u001b[0m| : | : |\n",
      "|\u001b[33mP\u001b[0m|\u001b[37mP\u001b[0m:\u001b[43m \u001b[0m| : |\n",
      "+---------+\n",
      "Taxi0-YELLOW: Fuel: 49/50, Location: (4, 2), Engine: ON, Collided: False, Step: 1, ALIVE\n",
      "Passenger0-YELLOW: Location: (4, 0), Destination: (-1, -1)\n",
      "Passenger1-RED: Location: (3, 0), Destination: (-1, -1)\n",
      "Passenger2-WHITE: Location: (4, 1), Destination: (-1, -1)\n",
      "Env done: False\n",
      "\n",
      "reward=-1\n",
      "term=False\n",
      "info={'events': [<Event.STEP: 1>, <Event.MOVE: 2>, <Event.HIT_OBSTACLE: 20>], 'dead': False, 'move_success': False, 'desired_action': 'south', 'performed_transition': 'south'}\n",
      "obs={obs}\n"
     ]
    }
   ],
   "source": [
    "single_taxi_env.reset()\n",
    "obs, reward, term, trunc, info = single_taxi_env.step(0)\n",
    "single_taxi_env.render()\n",
    "\n",
    "print(f'reward={reward}')\n",
    "print(f'term={term}')\n",
    "print(f'info={info}')\n",
    "print('obs={obs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0, 1, (99,), int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_taxi_env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['location_row',\n",
       " 'location_col',\n",
       " 'remaining_fuel',\n",
       " 'is_dead',\n",
       " 'passenger_0_location_row',\n",
       " 'passenger_0_location_col',\n",
       " 'passenger_0_picked_up',\n",
       " 'passenger_1_location_row',\n",
       " 'passenger_1_location_col',\n",
       " 'passenger_1_picked_up',\n",
       " 'passenger_2_location_row',\n",
       " 'passenger_2_location_col',\n",
       " 'passenger_2_picked_up']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_taxi_env.unwrapped.get_observation_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'south', 1: 'north', 2: 'east', 3: 'west', 4: 'pickup', 5: 'refuel'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_taxi_env.unwrapped.get_action_meanings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(6)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_taxi_env.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create expert agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from imitation.algorithms import bc\n",
    "from imitation.algorithms.dagger import SimpleDAggerTrainer\n",
    "from stable_baselines3.common.policies import BasePolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.decision_makers.Short_Term_Planner_DM import ST_Planner\n",
    "\n",
    "class PlannerPolicy(BasePolicy):\n",
    "    '''\n",
    "    an adaptor of the bfs planner to the imitation library\n",
    "    '''\n",
    "    env: gym.Env\n",
    "    planner = None\n",
    "\n",
    "    def __init__(self, env, planner):\n",
    "        super().__init__(env.observation_space, env.action_space)\n",
    "        self.env = env\n",
    "        self.planner = planner\n",
    "\n",
    "    def _predict(self, obs, deterministic=True):\n",
    "        return self.planner.get_action()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilay_menachem/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.state to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.state` for environment variables or `env.get_wrapper_attr('state')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/ilay_menachem/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.copy to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.copy` for environment variables or `env.get_wrapper_attr('copy')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SingleTaxiWrapper' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m vec_taxi_env \u001b[38;5;241m=\u001b[39m DummyVecEnv([\u001b[38;5;28;01mlambda\u001b[39;00m: single_taxi_env])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# needs different instintiation\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m planner \u001b[38;5;241m=\u001b[39m \u001b[43mST_Planner\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_space\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_taxi_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munwrapped\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_space\u001b[49m\u001b[43m,\u001b[49m\u001b[43mma_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_taxi_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m planner_policy \u001b[38;5;241m=\u001b[39m PlannerPolicy(single_taxi_env, planner)\n",
      "File \u001b[0;32m~/Documents/technion.nosync/thesis/multitaxi/MAC/src/decision_makers/Short_Term_Planner_DM.py:160\u001b[0m, in \u001b[0;36mST_Planner.__init__\u001b[0;34m(self, action_space, ma_env, agent_name, render)\u001b[0m\n\u001b[1;32m    158\u001b[0m     ma_env\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_state \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(ma_env\u001b[38;5;241m.\u001b[39mstate())\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msingle_problem \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_single_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mma_env\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43magent_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrender\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplan \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/technion.nosync/thesis/multitaxi/MAC/src/decision_makers/Short_Term_Planner_DM.py:108\u001b[0m, in \u001b[0;36mcreate_single_env\u001b[0;34m(ma_env, agent_name, render)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_single_env\u001b[39m(ma_env, agent_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaxi_0\u001b[39m\u001b[38;5;124m'\u001b[39m, render \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ma_env\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39mnum_taxis \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 108\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mma_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m         temp_env \u001b[38;5;241m=\u001b[39m TaxiEnv\u001b[38;5;241m.\u001b[39mparallel_env(\n\u001b[1;32m    111\u001b[0m             num_taxis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    112\u001b[0m             num_passengers\u001b[38;5;241m=\u001b[39mma_env\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39mnum_passengers,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    115\u001b[0m             field_of_view\u001b[38;5;241m=\u001b[39mma_env\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39mfield_of_view,\n\u001b[1;32m    116\u001b[0m             render_mode\u001b[38;5;241m=\u001b[39mma_env\u001b[38;5;241m.\u001b[39munwrapped\u001b[38;5;241m.\u001b[39mrender_mode)\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/gymnasium/core.py:315\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessing private attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is prohibited\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to get variables from other wrappers is deprecated and will be removed in v1.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get this variable you can do `env.unwrapped.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` for environment variables or `env.get_wrapper_attr(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` that will search the reminding wrappers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m )\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/gymnasium/core.py:315\u001b[0m, in \u001b[0;36mWrapper.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccessing private attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is prohibited\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    311\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menv.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to get variables from other wrappers is deprecated and will be removed in v1.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto get this variable you can do `env.unwrapped.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` for environment variables or `env.get_wrapper_attr(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)` that will search the reminding wrappers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    314\u001b[0m )\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SingleTaxiWrapper' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "vec_taxi_env = DummyVecEnv([lambda: single_taxi_env])\n",
    "\n",
    "# needs different instintiation\n",
    "planner = ST_Planner(action_space=single_taxi_env.unwrapped.action_space,ma_env=single_taxi_env)\n",
    "planner_policy = PlannerPolicy(single_taxi_env, planner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dagger training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bc_trainer = bc.BC(\n",
    "    observation_space=single_taxi_env.observation_space,\n",
    "    action_space=single_taxi_env.action_space,\n",
    "    rng=np.random.default_rng()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dagger_trainer = SimpleDAggerTrainer(\n",
    "    venv=vec_taxi_env,\n",
    "    scratch_dir='dagger_scratch',\n",
    "    expert_policy=planner_policy,\n",
    "    bc_trainer=bc_trainer,\n",
    "    rng=np.random.default_rng()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdagger_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrollout_round_min_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/imitation/algorithms/dagger.py:669\u001b[0m, in \u001b[0;36mSimpleDAggerTrainer.train\u001b[0;34m(self, total_timesteps, rollout_round_min_episodes, rollout_round_min_timesteps, bc_train_kwargs)\u001b[0m\n\u001b[1;32m    662\u001b[0m round_timestep_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    664\u001b[0m sample_until \u001b[38;5;241m=\u001b[39m rollout\u001b[38;5;241m.\u001b[39mmake_sample_until(\n\u001b[1;32m    665\u001b[0m     min_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(rollout_round_min_timesteps, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size),\n\u001b[1;32m    666\u001b[0m     min_episodes\u001b[38;5;241m=\u001b[39mrollout_round_min_episodes,\n\u001b[1;32m    667\u001b[0m )\n\u001b[0;32m--> 669\u001b[0m trajectories \u001b[38;5;241m=\u001b[39m \u001b[43mrollout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_trajectories\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpert_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollector\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_until\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_until\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m traj \u001b[38;5;129;01min\u001b[39;00m trajectories:\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39mrecord_mean(\n\u001b[1;32m    679\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdagger/mean_episode_reward\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    680\u001b[0m         np\u001b[38;5;241m.\u001b[39msum(traj\u001b[38;5;241m.\u001b[39mrews),\n\u001b[1;32m    681\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/imitation/data/rollout.py:446\u001b[0m, in \u001b[0;36mgenerate_trajectories\u001b[0;34m(policy, venv, sample_until, rng, deterministic_policy)\u001b[0m\n\u001b[1;32m    443\u001b[0m dones \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(venv\u001b[38;5;241m.\u001b[39mnum_envs, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(active):\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;66;03m# policy gets unwrapped observations (eg as dict, not dictobs)\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     acts, state \u001b[38;5;241m=\u001b[39m \u001b[43mget_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdones\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    447\u001b[0m     obs, rews, dones, infos \u001b[38;5;241m=\u001b[39m venv\u001b[38;5;241m.\u001b[39mstep(acts)\n\u001b[1;32m    448\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    449\u001b[0m         obs,\n\u001b[1;32m    450\u001b[0m         (np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mdict\u001b[39m),\n\u001b[1;32m    451\u001b[0m     ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuple observations are not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/imitation/data/rollout.py:319\u001b[0m, in \u001b[0;36mpolicy_to_callable.<locals>.get_actions\u001b[0;34m(observations, states, episode_starts)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(policy, (BaseAlgorithm, BasePolicy))\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# pytype doesn't seem to understand that policy is a BaseAlgorithm\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;66;03m# or BasePolicy here, rather than a Callable\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m (acts, states) \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pytype: disable=attribute-error\u001b[39;49;00m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepisode_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m acts, states\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/stable_baselines3/common/policies.py:368\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    365\u001b[0m obs_tensor, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 368\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# Convert to numpy, and reshape to the original action shape\u001b[39;00m\n\u001b[1;32m    370\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mshape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[47], line 16\u001b[0m, in \u001b[0;36mPlannerPolicy._predict\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplanner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_action\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_action'"
     ]
    }
   ],
   "source": [
    "dagger_trainer.train(total_timesteps=1_000_000, rollout_round_min_episodes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create DQN agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ilay_menachem/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/stable_baselines3/common/buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 550.72GB > 3.65GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for DQNPolicy:\n\tMissing key(s) in state_dict: \"q_net.q_net.0.weight\", \"q_net.q_net.0.bias\", \"q_net.q_net.2.weight\", \"q_net.q_net.2.bias\", \"q_net.q_net.4.weight\", \"q_net.q_net.4.bias\", \"q_net_target.q_net.0.weight\", \"q_net_target.q_net.0.bias\", \"q_net_target.q_net.2.weight\", \"q_net_target.q_net.2.bias\", \"q_net_target.q_net.4.weight\", \"q_net_target.q_net.4.bias\". \n\tUnexpected key(s) in state_dict: \"mlp_extractor.policy_net.0.weight\", \"mlp_extractor.policy_net.0.bias\", \"mlp_extractor.policy_net.2.weight\", \"mlp_extractor.policy_net.2.bias\", \"mlp_extractor.value_net.0.weight\", \"mlp_extractor.value_net.0.bias\", \"mlp_extractor.value_net.2.weight\", \"mlp_extractor.value_net.2.bias\", \"action_net.weight\", \"action_net.bias\", \"value_net.weight\", \"value_net.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m dqn_model \u001b[38;5;241m=\u001b[39m DQN(\n\u001b[1;32m      2\u001b[0m     policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     env\u001b[38;5;241m=\u001b[39msingle_taxi_env,\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m \u001b[43mdqn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdagger_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m dqn_model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/torch/nn/modules/module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for DQNPolicy:\n\tMissing key(s) in state_dict: \"q_net.q_net.0.weight\", \"q_net.q_net.0.bias\", \"q_net.q_net.2.weight\", \"q_net.q_net.2.bias\", \"q_net.q_net.4.weight\", \"q_net.q_net.4.bias\", \"q_net_target.q_net.0.weight\", \"q_net_target.q_net.0.bias\", \"q_net_target.q_net.2.weight\", \"q_net_target.q_net.2.bias\", \"q_net_target.q_net.4.weight\", \"q_net_target.q_net.4.bias\". \n\tUnexpected key(s) in state_dict: \"mlp_extractor.policy_net.0.weight\", \"mlp_extractor.policy_net.0.bias\", \"mlp_extractor.policy_net.2.weight\", \"mlp_extractor.policy_net.2.bias\", \"mlp_extractor.value_net.0.weight\", \"mlp_extractor.value_net.0.bias\", \"mlp_extractor.value_net.2.weight\", \"mlp_extractor.value_net.2.bias\", \"action_net.weight\", \"action_net.bias\", \"value_net.weight\", \"value_net.bias\". "
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "\n",
    "dqn_model = DQN(\n",
    "    policy=\"MlpPolicy\",\n",
    "    env=single_taxi_env\n",
    ")\n",
    "\n",
    "dqn_model.policy.load_state_dict(dagger_trainer.policy.state_dict())\n",
    "\n",
    "dqn_model.learn(total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "\n",
    "mean_reward, std_reward = evaluate_policy(dqn_model, single_taxi_env, n_eval_episodes=10)\n",
    "print(f\"Mean reward: {mean_reward:.2f} +/- {std_reward:.2f}\")\n",
    "\n",
    "dqn_model.save(\"dqn_dagger_single_taxi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3 import A2C, DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from stable_baselines3.common.callbacks import EvalCallback, CheckpointCallback\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.results_plotter import load_results, ts2xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"temp/\"\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must use `MultiInputPolicy` when working with dict observation space, not MlpPolicy",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m CheckpointCallback(save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50000\u001b[39m, save_path\u001b[38;5;241m=\u001b[39mlog_dir)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#agent = A2C(policy='MlpPolicy', env=single_taxi_env, verbose=0, gamma=0.99, n_steps=5, learning_rate=0.0007)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43mDQN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msingle_taxi_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexploration_final_eps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexploration_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/stable_baselines3/dqn/dqn.py:104\u001b[0m, in \u001b[0;36mDQN.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, target_update_interval, exploration_fraction, exploration_initial_eps, exploration_final_eps, max_grad_norm, stats_window_size, tensorboard_log, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     78\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[DQNPolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    103\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# No action noise\u001b[39;49;00m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDiscrete\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_initial_eps \u001b[38;5;241m=\u001b[39m exploration_initial_eps\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexploration_final_eps \u001b[38;5;241m=\u001b[39m exploration_final_eps\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:110\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     82\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[BasePolicy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     supported_action_spaces: Optional[Tuple[Type[spaces\u001b[38;5;241m.\u001b[39mSpace], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ):\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstats_window_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstats_window_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupport_multi_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size \u001b[38;5;241m=\u001b[39m buffer_size\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[0;32m~/miniforge3/envs/Mac_dbl/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:192\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, stats_window_size, tensorboard_log, verbose, device, support_multi_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Catch common mistake: using MlpPolicy/CnnPolicy instead of MultiInputPolicy\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m policy \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCnnPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, spaces\u001b[38;5;241m.\u001b[39mDict):\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must use `MultiInputPolicy` when working with dict observation space, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpolicy\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sde \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, spaces\u001b[38;5;241m.\u001b[39mBox):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneralized State-Dependent Exploration (gSDE) can only be used with continuous actions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: You must use `MultiInputPolicy` when working with dict observation space, not MlpPolicy"
     ]
    }
   ],
   "source": [
    "single_taxi_env = Monitor(single_taxi_env, log_dir)\n",
    "eval_callback = EvalCallback(single_taxi_env, best_model_save_path=log_dir, log_path=log_dir, eval_freq=1000, deterministic=True, render=False)\n",
    "checkpoint_callback = CheckpointCallback(save_freq=50000, save_path=log_dir)\n",
    "\n",
    "#agent = A2C(policy='MlpPolicy', env=single_taxi_env, verbose=0, gamma=0.99, n_steps=5, learning_rate=0.0007)\n",
    "agent = DQN(policy='MlpPolicy', env=single_taxi_env, verbose=0, gamma=0.95, batch_size=128, exploration_final_eps=0.1, exploration_fraction=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_reward=-137.90 +/- 31.00\n"
     ]
    }
   ],
   "source": [
    "def eval_policy(agent, env, n_eval_episodes=10):\n",
    "    mean_reward, std_reward = evaluate_policy(agent, env, n_eval_episodes=10)\n",
    "    print(f'mean_reward={mean_reward:.2f} +/- {std_reward:.2f}')\n",
    "\n",
    "eval_policy(agent, single_taxi_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43meval_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/dqn/dqn.py:267\u001b[0m, in \u001b[0;36mDQN.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfDQN,\n\u001b[1;32m    260\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    266\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfDQN:\n\u001b[0;32m--> 267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:328\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_freq, TrainFreq)  \u001b[38;5;66;03m# check done in _setup_learn()\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 328\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/off_policy_algorithm.py:560\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    557\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample_action(learning_starts, action_noise, env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    563\u001b[0m num_collected_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/wrappers/normalize.py:85\u001b[0m, in \u001b[0;36mNormalizeObservation.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     83\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(obs)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obs, rews, terminateds, truncateds, infos\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/wrappers/normalize.py:99\u001b[0m, in \u001b[0;36mNormalizeObservation.normalize\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnormalize\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Normalises the observation using the running mean and variance of the observations.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_rms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (obs \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_rms\u001b[38;5;241m.\u001b[39mmean) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_rms\u001b[38;5;241m.\u001b[39mvar \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepsilon)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/wrappers/normalize.py:22\u001b[0m, in \u001b[0;36mRunningMeanStd.update\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m batch_var \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m batch_count \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_from_moments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_count\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/wrappers/normalize.py:26\u001b[0m, in \u001b[0;36mRunningMeanStd.update_from_moments\u001b[0;34m(self, batch_mean, batch_var, batch_count)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_from_moments\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_mean, batch_var, batch_count):\n\u001b[1;32m     25\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Updates from batch mean, variance and count moments.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcount \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_mean_var_count_from_moments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_count\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/gymnasium/wrappers/normalize.py:41\u001b[0m, in \u001b[0;36mupdate_mean_var_count_from_moments\u001b[0;34m(mean, var, count, batch_mean, batch_var, batch_count)\u001b[0m\n\u001b[1;32m     39\u001b[0m m_a \u001b[38;5;241m=\u001b[39m var \u001b[38;5;241m*\u001b[39m count\n\u001b[1;32m     40\u001b[0m m_b \u001b[38;5;241m=\u001b[39m batch_var \u001b[38;5;241m*\u001b[39m batch_count\n\u001b[0;32m---> 41\u001b[0m M2 \u001b[38;5;241m=\u001b[39m m_a \u001b[38;5;241m+\u001b[39m m_b \u001b[38;5;241m+\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msquare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m count \u001b[38;5;241m*\u001b[39m batch_count \u001b[38;5;241m/\u001b[39m tot_count\n\u001b[1;32m     42\u001b[0m new_var \u001b[38;5;241m=\u001b[39m M2 \u001b[38;5;241m/\u001b[39m tot_count\n\u001b[1;32m     43\u001b[0m new_count \u001b[38;5;241m=\u001b[39m tot_count\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.learn(total_timesteps=250_000, callback=[eval_callback, checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = load_results(log_dir)\n",
    "x, y = ts2xy(results, 'timesteps')\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('Timesteps')\n",
    "plt.ylabel('Rewards')\n",
    "plt.title('Single Taxi')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "| : : : : |\n",
      "| : :\u001b[37mP\u001b[0m: :\u001b[33mP\u001b[0m|\n",
      "| : : : : |\n",
      "| : : : : |\n",
      "|\u001b[31mP\u001b[0m: : : :\u001b[43m \u001b[0m|\n",
      "+---------+\n",
      "Taxi0-YELLOW: Fuel: 2/50, Location: (4, 4), Engine: ON, Collided: False, Step: 32, ALIVE\n",
      "Passenger0-YELLOW: Location: (1, 4), Destination: (-1, -1)\n",
      "Passenger1-RED: Location: (4, 0), Destination: (-1, -1)\n",
      "Passenger2-WHITE: Location: (1, 2), Destination: (-1, -1)\n",
      "Env done: False\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def sample_trajectory(env, agent):\n",
    "    obs = env.reset()[0]\n",
    "\n",
    "    for _ in range(100):\n",
    "        action, _ = agent.predict(obs)\n",
    "        obs, _, done, _, _ = env.step(int(action))\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        print(env.render())\n",
    "        time.sleep(0.1)\n",
    "        clear_output(wait=True)\n",
    "\n",
    "sample_trajectory(single_taxi_env, agent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
